{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012335,
     "end_time": "2020-08-29T09:36:15.958969",
     "exception": false,
     "start_time": "2020-08-29T09:36:15.946634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "In this Notebook i have done binary classification of Sentiment on a dataset that contains annotated Bangla texts.I have tried to use a deep learning based hybrid network with CNN an LSTM.Through hyper parameter tuning,i have achieved an accuracy of 84% with somewhat overfitting.\n",
    "\n",
    "My main focus of this notebook is to see the impact of hybrid CNN-BiLSTM model in bangla sentiment analysis and newbie Bangla NLP researchers like me can get a better intution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011719,
     "end_time": "2020-08-29T09:36:15.981279",
     "exception": false,
     "start_time": "2020-08-29T09:36:15.969560",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Library & Package Import\n",
    "I have used KERAS to implement CNN and LSTM in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T09:36:16.013048Z",
     "iopub.status.busy": "2020-08-29T09:36:16.010776Z",
     "iopub.status.idle": "2020-08-29T09:36:24.626305Z",
     "shell.execute_reply": "2020-08-29T09:36:24.625558Z"
    },
    "papermill": {
     "duration": 8.634984,
     "end_time": "2020-08-29T09:36:24.626494",
     "exception": false,
     "start_time": "2020-08-29T09:36:15.991510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-13 01:24:02.181766: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-13 01:24:02.181809: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_excel\n",
    "import numpy as np\n",
    "import re\n",
    "from re import sub\n",
    "import multiprocessing\n",
    "from unidecode import unidecode\n",
    "import os\n",
    "from time import time \n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dense,Dropout,Activation,Embedding,Flatten,Bidirectional,MaxPooling2D, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "#from tensorflow.keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import h5py\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the Keras model\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(num_distinct_words, embedding_output_dims, input_length=max_sequence_length))\n",
    "# model.add(Bidirectional(LSTM(10), merge_mode='sum'))\n",
    "# model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009881,
     "end_time": "2020-08-29T09:36:24.646568",
     "exception": false,
     "start_time": "2020-08-29T09:36:24.636687",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predefined Functions \n",
    "I have predefined some functions for the preprocessing of my texts.The dataset contains raw text data that have many unwanted things\n",
    "(Punctuations,English words,emojis etc..).I have cleaned this things with my function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T09:36:24.682336Z",
     "iopub.status.busy": "2020-08-29T09:36:24.681181Z",
     "iopub.status.idle": "2020-08-29T09:36:24.683917Z",
     "shell.execute_reply": "2020-08-29T09:36:24.684510Z"
    },
    "papermill": {
     "duration": 0.028242,
     "end_time": "2020-08-29T09:36:24.684693",
     "exception": false,
     "start_time": "2020-08-29T09:36:24.656451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text_to_word_list(text):\n",
    "    text = text.split()\n",
    "    return text\n",
    "\n",
    "def replace_strings(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           u\"\\u00C0-\\u017F\"          #latin\n",
    "                           u\"\\u2000-\\u206F\"          #generalPunctuations\n",
    "                               \n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    english_pattern=re.compile('[a-zA-Z0-9]+', flags=re.I)\n",
    "    #latin_pattern=re.compile('[A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00f6\\u00f8-\\u00ff\\s]*',)\n",
    "    \n",
    "    text=emoji_pattern.sub(r'', text)\n",
    "    text=english_pattern.sub(r'', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def remove_punctuations(my_str):\n",
    "    # define punctuation\n",
    "    punctuations = '''```\u0012\u0010\u0002\b`\u0007\b£|¢|\u0007Ñ+-*/=EROero৳০১২৩৪৫৬৭৮৯012–34567•89।!()-[]{};:'\"“\\’,<>./?@#$%^&*_~‘—॥”‰⚽️✌�￰৷￰'''\n",
    "    \n",
    "    no_punct = \"\"\n",
    "    for char in my_str:\n",
    "        if char not in punctuations:\n",
    "            no_punct = no_punct + char\n",
    "\n",
    "    # display the unpunctuated string\n",
    "    return no_punct\n",
    "\n",
    "\n",
    "\n",
    "def joining(text):\n",
    "    out=' '.join(text)\n",
    "    return out\n",
    "\n",
    "def preprocessing(text):\n",
    "    out=remove_punctuations(replace_strings(text))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009759,
     "end_time": "2020-08-29T09:36:24.704583",
     "exception": false,
     "start_time": "2020-08-29T09:36:24.694824",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Import\n",
    "The data is in excel file.I have about 6500+ in this dataset.The data is either positive or negative.\n",
    "I have annotated \"0\" as Negative and \"1\" as Positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T09:36:24.730380Z",
     "iopub.status.busy": "2020-08-29T09:36:24.729640Z",
     "iopub.status.idle": "2020-08-29T09:36:25.754179Z",
     "shell.execute_reply": "2020-08-29T09:36:25.754875Z"
    },
    "papermill": {
     "duration": 1.040497,
     "end_time": "2020-08-29T09:36:25.755049",
     "exception": false,
     "start_time": "2020-08-29T09:36:24.714552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>মুগ্ধ হয়ে গেলাম মামু. আর তোমায় কি কমু. বলো তোম...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>এই কুত্তার বাচ্চাদের জন্য দেশটা আজ এমন অবস্তায়...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ভাই আপনার কথাই যাদু রয়েছে</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>উওরটা আমার অনেক ভাল লেগেছে</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>আমার নিজের গাড়ী নিয়ে কি সাজেক যেতে পারবো না ?...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>ঐ পুলিশ কুওারবাচচাদের গুলিকরে মেরে ফেলা উচিত</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>খিচুড়ি পর্ব মারাত্মক । বাকি টা দেখি তারপর কমেন্ট</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>পাশের ফ্রেন্ডটা কি ছেলে না মেয়ে</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>মদ লকমান না খেলেও আমরা খাই এমনটাই মনে হচ্ছে</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>এইসমস্ত হায়েনা দের কোনো জেল না দিয়ে ফাঁসি দিয়ে...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14161 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Data  Label\n",
       "0     মুগ্ধ হয়ে গেলাম মামু. আর তোমায় কি কমু. বলো তোম...      1\n",
       "1     এই কুত্তার বাচ্চাদের জন্য দেশটা আজ এমন অবস্তায়...      2\n",
       "2                             ভাই আপনার কথাই যাদু রয়েছে      1\n",
       "3                           উওরটা আমার অনেক ভাল লেগেছে       1\n",
       "4     আমার নিজের গাড়ী নিয়ে কি সাজেক যেতে পারবো না ?...      0\n",
       "...                                                 ...    ...\n",
       "1581       ঐ পুলিশ কুওারবাচচাদের গুলিকরে মেরে ফেলা উচিত      2\n",
       "1582   খিচুড়ি পর্ব মারাত্মক । বাকি টা দেখি তারপর কমেন্ট      1\n",
       "1583                   পাশের ফ্রেন্ডটা কি ছেলে না মেয়ে       2\n",
       "1584        মদ লকমান না খেলেও আমরা খাই এমনটাই মনে হচ্ছে      2\n",
       "1585  এইসমস্ত হায়েনা দের কোনো জেল না দিয়ে ফাঁসি দিয়ে...      2\n",
       "\n",
       "[14161 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#df=pd.read_excel('/kaggle/input/pseudolabel/predicted_unsupervised_sentiment.xlsx')\n",
    "df=pd.read_csv(\"/home/ubuntu/Desktop/ML/Coding/dataset/SentNoB Dataset/Train.csv\",encoding='utf-8')\n",
    "df_test=pd.read_csv(\"/home/ubuntu/Desktop/ML/Coding/dataset/SentNoB Dataset/Test.csv\",encoding='utf-8')\n",
    "df=df.append(df_test);\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010147,
     "end_time": "2020-08-29T09:36:25.775608",
     "exception": false,
     "start_time": "2020-08-29T09:36:25.765461",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we will visualize the ratio of Postive and Negative sentiment.We can see that the ratio is closly 1:1.Which is considered as a good balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=[\"sentence\",\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"sentiment\"].replace({2:1}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>মুগ্ধ হয়ে গেলাম মামু. আর তোমায় কি কমু. বলো তোম...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>এই কুত্তার বাচ্চাদের জন্য দেশটা আজ এমন অবস্তায়...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ভাই আপনার কথাই যাদু রয়েছে</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>উওরটা আমার অনেক ভাল লেগেছে</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>আমার নিজের গাড়ী নিয়ে কি সাজেক যেতে পারবো না ?...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>ঐ পুলিশ কুওারবাচচাদের গুলিকরে মেরে ফেলা উচিত</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>খিচুড়ি পর্ব মারাত্মক । বাকি টা দেখি তারপর কমেন্ট</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>পাশের ফ্রেন্ডটা কি ছেলে না মেয়ে</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>মদ লকমান না খেলেও আমরা খাই এমনটাই মনে হচ্ছে</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>এইসমস্ত হায়েনা দের কোনো জেল না দিয়ে ফাঁসি দিয়ে...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14161 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  sentiment\n",
       "0     মুগ্ধ হয়ে গেলাম মামু. আর তোমায় কি কমু. বলো তোম...          1\n",
       "1     এই কুত্তার বাচ্চাদের জন্য দেশটা আজ এমন অবস্তায়...          2\n",
       "2                             ভাই আপনার কথাই যাদু রয়েছে          1\n",
       "3                           উওরটা আমার অনেক ভাল লেগেছে           1\n",
       "4     আমার নিজের গাড়ী নিয়ে কি সাজেক যেতে পারবো না ?...          0\n",
       "...                                                 ...        ...\n",
       "1581       ঐ পুলিশ কুওারবাচচাদের গুলিকরে মেরে ফেলা উচিত          2\n",
       "1582   খিচুড়ি পর্ব মারাত্মক । বাকি টা দেখি তারপর কমেন্ট          1\n",
       "1583                   পাশের ফ্রেন্ডটা কি ছেলে না মেয়ে           2\n",
       "1584        মদ লকমান না খেলেও আমরা খাই এমনটাই মনে হচ্ছে          2\n",
       "1585  এইসমস্ত হায়েনা দের কোনো জেল না দিয়ে ফাঁসি দিয়ে...          2\n",
       "\n",
       "[14161 rows x 2 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T09:36:25.806555Z",
     "iopub.status.busy": "2020-08-29T09:36:25.805699Z",
     "iopub.status.idle": "2020-08-29T09:36:26.033378Z",
     "shell.execute_reply": "2020-08-29T09:36:26.032638Z"
    },
    "papermill": {
     "duration": 0.24749,
     "end_time": "2020-08-29T09:36:26.033522",
     "exception": false,
     "start_time": "2020-08-29T09:36:25.786032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(df['sentiment']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010247,
     "end_time": "2020-08-29T09:36:26.054394",
     "exception": false,
     "start_time": "2020-08-29T09:36:26.044147",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Preprocessing\n",
    "At first we will clean the dataset with my predefined function preprocessing()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T09:36:26.092237Z",
     "iopub.status.busy": "2020-08-29T09:36:26.087017Z",
     "iopub.status.idle": "2020-08-29T09:36:26.408188Z",
     "shell.execute_reply": "2020-08-29T09:36:26.407407Z"
    },
    "papermill": {
     "duration": 0.343238,
     "end_time": "2020-08-29T09:36:26.408317",
     "exception": false,
     "start_time": "2020-08-29T09:36:26.065079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['sentence'] = df.sentence.apply(lambda x: preprocessing(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T09:36:26.436809Z",
     "iopub.status.busy": "2020-08-29T09:36:26.435760Z",
     "iopub.status.idle": "2020-08-29T09:36:26.439100Z",
     "shell.execute_reply": "2020-08-29T09:36:26.438502Z"
    },
    "papermill": {
     "duration": 0.019937,
     "end_time": "2020-08-29T09:36:26.439290",
     "exception": false,
     "start_time": "2020-08-29T09:36:26.419353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010308,
     "end_time": "2020-08-29T09:36:26.460311",
     "exception": false,
     "start_time": "2020-08-29T09:36:26.450003",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now I will prepare the dataset to train in the CNN LSTM network.So i have to convert all Sentences into a numpy Array.\n",
    "\n",
    "I have divided the training and testing data into 80/20 ratio.\n",
    "\n",
    "I have converted the sentiment values into one hot encodings for the convenient use in model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T09:36:26.498814Z",
     "iopub.status.busy": "2020-08-29T09:36:26.497605Z",
     "iopub.status.idle": "2020-08-29T09:36:26.620647Z",
     "shell.execute_reply": "2020-08-29T09:36:26.619161Z"
    },
    "papermill": {
     "duration": 0.149615,
     "end_time": "2020-08-29T09:36:26.620833",
     "exception": false,
     "start_time": "2020-08-29T09:36:26.471218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Length: 12570\n",
      "Testing Set Length: 1591\n",
      "training_sentences shape: (12570,)\n",
      "testing_sentences shape: (1591,)\n",
      "train_labels shape: (12570, 3)\n",
      "test_labels shape: (1591, 3)\n"
     ]
    }
   ],
   "source": [
    "#train1, test1 = train_test_split(df,random_state=69, test_size=0.2)\n",
    "\n",
    "train1=df[:12570]\n",
    "test1=df[12570:]\n",
    "\n",
    "training_sentences = []\n",
    "testing_sentences = []\n",
    "\n",
    "\n",
    "\n",
    "train_sentences=train1['sentence'].values\n",
    "train_labels=train1['sentiment'].values\n",
    "for i in range(train_sentences.shape[0]): \n",
    "    #print(train_sentences[i])\n",
    "    x=str(train_sentences[i])\n",
    "    training_sentences.append(x)\n",
    "    \n",
    "training_sentences=np.array(training_sentences)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_sentences=test1['sentence'].values\n",
    "test_labels=test1['sentiment'].values\n",
    "\n",
    "for i in range(test_sentences.shape[0]): \n",
    "    x=str(test_sentences[i])\n",
    "    testing_sentences.append(x)\n",
    "    \n",
    "testing_sentences=np.array(testing_sentences)\n",
    "\n",
    "\n",
    "train_labels=to_categorical(train_labels)\n",
    "\n",
    "\n",
    "test_labels=to_categorical(test_labels)\n",
    "print(\"Training Set Length: \"+str(len(train1)))\n",
    "print(\"Testing Set Length: \"+str(len(test1)))\n",
    "print(\"training_sentences shape: \"+str(training_sentences.shape))\n",
    "print(\"testing_sentences shape: \"+str(testing_sentences.shape))\n",
    "print(\"train_labels shape: \"+str(train_labels.shape))\n",
    "print(\"test_labels shape: \"+str(test_labels.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010413,
     "end_time": "2020-08-29T09:36:26.642686",
     "exception": false,
     "start_time": "2020-08-29T09:36:26.632273",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The Processed result is here what you see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T09:36:26.670803Z",
     "iopub.status.busy": "2020-08-29T09:36:26.670015Z",
     "iopub.status.idle": "2020-08-29T09:36:26.674314Z",
     "shell.execute_reply": "2020-08-29T09:36:26.673563Z"
    },
    "papermill": {
     "duration": 0.020899,
     "end_time": "2020-08-29T09:36:26.674467",
     "exception": false,
     "start_time": "2020-08-29T09:36:26.653568",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "এই কুত্তার বাচ্চাদের জন্য দেশটা আজ এমন অবস্তায় এই তিনটা পুলিশ কে তরে সবার সামনে মেরে পেলা দরকার \n",
      "[0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(training_sentences[1])\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01087,
     "end_time": "2020-08-29T09:36:26.696569",
     "exception": false,
     "start_time": "2020-08-29T09:36:26.685699",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now i will predefine some variables.\n",
    "\n",
    "vocab_size is the maximum vocabulary length of Tokenizer.\n",
    "\n",
    "KERAS tokenzier allows to vectorize a text corpus, by turning each text into either a sequence of integers (each integer being the index of a token in a dictionary) or into a vector where the coefficient for each token could be binary, based on word count, based on tf-idf...\n",
    "\n",
    "I will be tokenizing my dataset with this class here.I have did this tokenization so that it can be later used to generate Embeddings.\n",
    "\n",
    "The main advantage of word embedding is that words that share a similar context can be represented close to each other in the vector space. Thus, vectors carry a sense of semantic of a word.\n",
    "\n",
    "I have predefined the embedding dimension as 300(embedding_dim).\n",
    "\n",
    "max_length is the sentence maximum length.\n",
    "\n",
    "trunc_type is the truncation type.\n",
    "\n",
    "oov_token is the token for the words that are not present in the corpus.oov means out of vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T09:36:26.726011Z",
     "iopub.status.busy": "2020-08-29T09:36:26.724863Z",
     "iopub.status.idle": "2020-08-29T09:36:26.728118Z",
     "shell.execute_reply": "2020-08-29T09:36:26.727446Z"
    },
    "papermill": {
     "duration": 0.02028,
     "end_time": "2020-08-29T09:36:26.728248",
     "exception": false,
     "start_time": "2020-08-29T09:36:26.707968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vocab_size = 25000\n",
    "# embedding_dim = 300\n",
    "# max_length = 100\n",
    "vocab_size = 50000\n",
    "embedding_dim = 300\n",
    "max_length = 100\n",
    "trunc_type='post'\n",
    "oov_tok = \"<OOV>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T09:36:26.756605Z",
     "iopub.status.busy": "2020-08-29T09:36:26.755773Z",
     "iopub.status.idle": "2020-08-29T09:36:26.760382Z",
     "shell.execute_reply": "2020-08-29T09:36:26.759595Z"
    },
    "papermill": {
     "duration": 0.02122,
     "end_time": "2020-08-29T09:36:26.760560",
     "exception": false,
     "start_time": "2020-08-29T09:36:26.739340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12570,)\n",
      "(12570, 3)\n"
     ]
    }
   ],
   "source": [
    "print(training_sentences.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010435,
     "end_time": "2020-08-29T09:36:26.782197",
     "exception": false,
     "start_time": "2020-08-29T09:36:26.771762",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "At first i will tokenize and then i will be padding the sequences.I have used tokenizer only on training dataset to see how the model performs on unseen words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T09:36:26.838716Z",
     "iopub.status.busy": "2020-08-29T09:36:26.833416Z",
     "iopub.status.idle": "2020-08-29T09:36:27.475648Z",
     "shell.execute_reply": "2020-08-29T09:36:27.474948Z"
    },
    "papermill": {
     "duration": 0.682778,
     "end_time": "2020-08-29T09:36:27.475798",
     "exception": false,
     "start_time": "2020-08-29T09:36:26.793020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23811\n",
      "Word index length:23811\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "print(len(word_index))\n",
    "print(\"Word index length:\"+str(len(tokenizer.word_index)))\n",
    "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "padded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type)\n",
    "\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad_sequences(test_sequences,maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T09:36:27.509504Z",
     "iopub.status.busy": "2020-08-29T09:36:27.508080Z",
     "iopub.status.idle": "2020-08-29T09:36:27.513977Z",
     "shell.execute_reply": "2020-08-29T09:36:27.513188Z"
    },
    "papermill": {
     "duration": 0.026912,
     "end_time": "2020-08-29T09:36:27.514109",
     "exception": false,
     "start_time": "2020-08-29T09:36:27.487197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence :--> \n",
      "\n",
      "ভাই আপনার কথাই যাদু রয়েছে\n",
      "\n",
      "Sentence Tokenized and Converted into Sequence :--> \n",
      "\n",
      "[3, 9, 1380, 11381, 1471]\n",
      "\n",
      "After Padding the Sequence with padding length 100 :--> \n",
      "\n",
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     3\n",
      "     9  1380 11381  1471]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentence :--> \\n\")\n",
    "print(training_sentences[2]+\"\\n\")\n",
    "print(\"Sentence Tokenized and Converted into Sequence :--> \\n\")\n",
    "print(str(sequences[2])+\"\\n\")\n",
    "print(\"After Padding the Sequence with padding length 100 :--> \\n\")\n",
    "print(padded[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T09:36:27.543526Z",
     "iopub.status.busy": "2020-08-29T09:36:27.542369Z",
     "iopub.status.idle": "2020-08-29T09:36:27.546103Z",
     "shell.execute_reply": "2020-08-29T09:36:27.546711Z"
    },
    "papermill": {
     "duration": 0.021501,
     "end_time": "2020-08-29T09:36:27.546874",
     "exception": false,
     "start_time": "2020-08-29T09:36:27.525373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded shape(training): (12570, 100)\n",
      "Padded shape(testing): (1591, 100)\n"
     ]
    }
   ],
   "source": [
    "print(\"Padded shape(training): \"+str(padded.shape))\n",
    "print(\"Padded shape(testing): \"+str(testing_padded.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010891,
     "end_time": "2020-08-29T09:36:27.569346",
     "exception": false,
     "start_time": "2020-08-29T09:36:27.558455",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Creation\n",
    "At first i have created embeddings from the text.\n",
    "\n",
    "In first layer,i created an conv1D with 200 as filter for CNN.\n",
    "\n",
    "In second & third layer,i have applied two Bi-LSTM with a dropout of .5.\n",
    "\n",
    "In rest of the layer i have applied Dense network.\n",
    "\n",
    "I have used Adap Optimizer with fine tuned hyperparameters.\n",
    "\n",
    "I have also applied L2 regularizations to reduce overfitting as much as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T09:36:27.654474Z",
     "iopub.status.busy": "2020-08-29T09:36:27.609646Z",
     "iopub.status.idle": "2020-08-29T09:36:29.255587Z",
     "shell.execute_reply": "2020-08-29T09:36:29.256625Z"
    },
    "papermill": {
     "duration": 1.676288,
     "end_time": "2020-08-29T09:36:29.256866",
     "exception": false,
     "start_time": "2020-08-29T09:36:27.580578",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, 100, 300)          15000000  \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 98, 200)           180200    \n",
      "                                                                 \n",
      " bidirectional_12 (Bidirecti  (None, 98, 128)          135680    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 98, 128)           0         \n",
      "                                                                 \n",
      " bidirectional_13 (Bidirecti  (None, 128)              98816     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 50)                6450      \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 100)               5100      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 3)                 303       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,429,099\n",
      "Trainable params: 15,429,099\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    model= Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
    "    model.add(Conv1D(200, kernel_size=3, activation = \"relu\"))\n",
    "    model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Bidirectional(LSTM(64)))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    #l2 regularizer\n",
    "    model.add(Dense(100,kernel_regularizer=regularizers.l2(0.01),activation=\"relu\"))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    #sgd= SGD(lr=0.0001,decay=1e-6,momentum=0.9,nesterov=True)\n",
    "    adam=Adam(learning_rate=0.0005,beta_1=0.9,beta_2=0.999,epsilon=1e-07,amsgrad=False)\n",
    "    model.summary()\n",
    "    #model.compile(loss='categorical_crossentropy',optimizer=adam,metrics=['accuracy'])\n",
    "    model.compile(loss='mse',optimizer=adam,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011167,
     "end_time": "2020-08-29T09:36:29.280669",
     "exception": false,
     "start_time": "2020-08-29T09:36:29.269502",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I trained the model for 5 epochs with batch size 256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T09:36:29.311730Z",
     "iopub.status.busy": "2020-08-29T09:36:29.310823Z",
     "iopub.status.idle": "2020-08-29T09:38:37.443524Z",
     "shell.execute_reply": "2020-08-29T09:38:37.444669Z"
    },
    "papermill": {
     "duration": 128.152726,
     "end_time": "2020-08-29T09:38:37.444972",
     "exception": false,
     "start_time": "2020-08-29T09:36:29.292246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "    history=model.fit(padded,train_labels,epochs=20,batch_size=256,validation_data=(testing_padded,test_labels),use_multiprocessing=True, workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018598,
     "end_time": "2020-08-29T09:38:37.521676",
     "exception": false,
     "start_time": "2020-08-29T09:38:37.503078",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T09:38:37.581894Z",
     "iopub.status.busy": "2020-08-29T09:38:37.572994Z",
     "iopub.status.idle": "2020-08-29T09:38:38.037272Z",
     "shell.execute_reply": "2020-08-29T09:38:38.036479Z"
    },
    "papermill": {
     "duration": 0.496359,
     "end_time": "2020-08-29T09:38:38.037405",
     "exception": false,
     "start_time": "2020-08-29T09:38:37.541046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show()\n",
    "\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy= history.history['val_accuracy']\n",
    "plt.plot(accuracy)\n",
    "plt.plot(val_accuracy)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['accuracy', 'val_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023061,
     "end_time": "2020-08-29T09:38:38.080221",
     "exception": false,
     "start_time": "2020-08-29T09:38:38.057160",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Accuracy and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-29T09:38:38.139699Z",
     "iopub.status.busy": "2020-08-29T09:38:38.138694Z",
     "iopub.status.idle": "2020-08-29T09:38:45.824071Z",
     "shell.execute_reply": "2020-08-29T09:38:45.823402Z"
    },
    "papermill": {
     "duration": 7.718225,
     "end_time": "2020-08-29T09:38:45.824208",
     "exception": false,
     "start_time": "2020-08-29T09:38:38.105983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#accuracy calculation\n",
    "loss_and_metrics = model.evaluate(padded,train_labels,batch_size=256)\n",
    "print(\"The train accuracy is: \"+str(loss_and_metrics[1]))\n",
    "loss_and_metrics = model.evaluate(testing_padded,test_labels,batch_size=256)\n",
    "print(\"The test accuracy is: \"+str(loss_and_metrics[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020779,
     "end_time": "2020-08-29T09:38:45.866851",
     "exception": false,
     "start_time": "2020-08-29T09:38:45.846072",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusion\n",
    "As we can see that the result is somewhat overfitting.This is because the dataset is very small to work with with deep learning.But my main focus of this notebook was to see what is the result of bangla sentiment analysis if i use a hybrid network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.020894,
     "end_time": "2020-08-29T09:38:45.908871",
     "exception": false,
     "start_time": "2020-08-29T09:38:45.887977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "papermill": {
   "duration": 155.662062,
   "end_time": "2020-08-29T09:38:46.039670",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-08-29T09:36:10.377608",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
