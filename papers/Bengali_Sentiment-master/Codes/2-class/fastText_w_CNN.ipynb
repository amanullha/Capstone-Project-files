{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fastText w/ CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CURzvVldMJcU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip3 install http://download.pytorch.org/whl/cu80/torch-0.4.1-cp36-cp36m-linux_x86_64.whl \n",
        "!pip3 install torch===1.4.0 torchvision===0.5.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNipBxSKYZMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLTbqNzdwSQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlmO6A_kQaCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import os\n",
        "# os.chdir('/content/drive/My Drive/Research_Shanto/Shanto/Packages/imbalanced-dataset-sampler-master')\n",
        "# !python setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnUazzVHSuB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "# import torch.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoG0sjo0Bu09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aa = np.zeros(((3,4,7)))\n",
        "\n",
        "bb = tuple([each.data for each in aa])\n",
        "print(bb[1])\n",
        "print(aa.shape)\n",
        "aa = aa[:,-1,:]\n",
        "print(aa.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58j7jIRoEpQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.tensor([[ [1, 2, 3], [2,4,1] ]])\n",
        "# print(\"aa permute \",x.permute(1,0).shape )\n",
        "print(x.shape)\n",
        "# print(x.unsqueeze(1).shape)\n",
        "x = x.squeeze(0)\n",
        "print(x.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q72g6eRGSuCA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
        "d = torch.tensor([[1.0, 1.0], [0.0, 1.0]])\n",
        "e = torch.matmul(c, d)\n",
        "print(e)\n",
        "print(c.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "855r1t0MSuCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Automatic differentiation with PyTorch\n",
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "\n",
        "# an operation of tensor\n",
        "y = x + 2 # y inherits grad_fn\n",
        "\n",
        "# apply operations on y\n",
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "\n",
        "print(out)\n",
        "\n",
        "out.backward()\n",
        "\n",
        "print(x.grad) # d(out)/dx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6j5_2wFSuCL",
        "colab_type": "text"
      },
      "source": [
        "### 2.2 Transforming Tensors\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT8u_3rzSuCL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "print(\"X shape: \", x.size())\n",
        "\n",
        "# add dimension\n",
        "print(x.unsqueeze(1).size()) \n",
        "\n",
        "# transpose \n",
        "torch.transpose(x, 0,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ggtl1m6aSuCP",
        "colab_type": "text"
      },
      "source": [
        "## 3. Emotion Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_JqoUiTSuCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import time\n",
        "from collections import defaultdict\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import itertools\n",
        "import csv\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import spacy\n",
        "\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "import logging\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "import multiprocessing\n",
        "from gensim.models import FastText as fText\n",
        "# from torchsampler import ImbalancedDatasetSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVCiiFsBNbuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Helper functions\n",
        "import pickle\n",
        "\n",
        "def convert_to_pickle(item, directory):\n",
        "    pickle.dump(item, open(directory,\"wb\"))\n",
        "\n",
        "\n",
        "def load_from_pickle(directory):\n",
        "    return pickle.load(open(directory,\"rb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bliFaijvNfIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ### read data from your Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL13k23-UL5V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !google-drive-ocamlfuse ~/google-drive\n",
        "# !fusermount -u ~/google-drive\n",
        "# # !google-drive-ocamlfuse drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2qHNv2-N9BC",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2sYWY79SuCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load data\n",
        "data = pd.read_csv(\"/content/drive/My Drive/Research_Shanto/Datasets/Ashik Bhai_Sentiment/ashik_dataset_2.csv\")\n",
        "# data = load_from_pickle(directory=\"../input/data-input/merged_training.pkl\")\n",
        "# data[\"Sentiment\"] = data[\"Sentiment\"].astype('str') \n",
        "def get_top_data(top_n = 3000):\n",
        "    top_data_df_positive1 = data[data['Sentiment'] == 1].head(top_n)\n",
        "    top_data_df_negative1 = data[data['Sentiment'] == -1].head(top_n)\n",
        "    top_data_df_neutral = data[data['Sentiment'] == 0].head(top_n)\n",
        "    top_data_df_positive2 = data[data['Sentiment'] == 2].head(top_n)\n",
        "    top_data_df_negetive2 = data[data['Sentiment'] == -2].head(top_n)\n",
        "    top_data_df_small = pd.concat([top_data_df_positive1, top_data_df_negative1, top_data_df_neutral,top_data_df_positive2,top_data_df_negetive2 ])\n",
        "    return top_data_df_small\n",
        "\n",
        "\n",
        "# Function call to get the top 3000 from each sentiment\n",
        "data[\"Sentiment\"].replace({1:1, 2:1, 0:0, -1:2, -2:2 },inplace=True)\n",
        "# data = get_top_data(top_n=3000)\n",
        "data = data[data.Sentiment != 0]\n",
        "data[\"Sentiment\"].replace({2:0},inplace=True)\n",
        "# Reducing to 3 sentiment\n",
        "\n",
        "print(data.dtypes)\n",
        "# data[\"Sentiment\"].replace({\"0\": \"Neutral\", \"1\": \"Positive\", \"2\": \"Positive\", \"-1\": \"Negetive\", \"-2\": \"Negetive\"},inplace=True)\n",
        "\n",
        "data.Sentiment.value_counts().plot.bar()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twNSP0G-SuCV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(data.head(10))\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nI00TmkSuCY",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 Preprocessing Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbRHe3kqbfwQ",
        "colab_type": "text"
      },
      "source": [
        "Pre-Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVCHxi2ASuCZ",
        "colab_type": "text"
      },
      "source": [
        "#### Tokenization and Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYDgIXGGSuCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# retain only text that contain less that 70 tokens to avoid too much padding\n",
        "# seq = 377\n",
        "data[\"token_size\"] = data[\"Data\"].apply(lambda x: len(x))\n",
        "# data = data.loc[data['token_size'] < seq].copy()\n",
        "\n",
        "\n",
        "# sampling\n",
        "data = data.sample(n=13779);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Flkk_rbauDbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bNrOA7mSuCe",
        "colab_type": "text"
      },
      "source": [
        "#### Constructing Vocabulary and Index-Word Mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFiuyauPPiXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fastText_wv = Word2Vec.load(\"/content/drive/My Drive/Research_Shanto/pretrained/BengWord2Vec/BengWord2Vec/posts.bin\")\n",
        "weights = torch.FloatTensor(fastText_wv.wv.vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRcGil6HJwvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa \n",
        "# (e.g., 5 -> \"dad\") for the dataset\n",
        "class ConstructVocab():\n",
        "    def __init__(self, sentences):\n",
        "        self.sentences = sentences\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "        self.create_index()\n",
        "        \n",
        "    def create_index(self):\n",
        "        # for s in self.sentences:\n",
        "        #     # update with individual tokens\n",
        "        #     self.vocab.update(s.split())\n",
        "            # update with individual tokens\n",
        "            \n",
        "        self.vocab.update(self.sentences)\n",
        "            \n",
        "        # sort the vocab\n",
        "        self.vocab = sorted(self.vocab)\n",
        "#         print(self.vocab)\n",
        "        \n",
        "\n",
        "        # add a padding token with index 0\n",
        "        self.word2idx['<pad>'] = 0\n",
        "        \n",
        "        # word to index mapping\n",
        "        for index, word in enumerate(self.vocab):\n",
        "            if word == self.vocab[-1]:\n",
        "                self.word2idx[word] = 0\n",
        "            else:\n",
        "                self.word2idx[word] = index + 1 # +1 because of pad token\n",
        "        \n",
        "        # index to word mapping\n",
        "        for word, index in self.word2idx.items():\n",
        "            self.idx2word[index] = word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdFasv0ASuCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# construct vocab and indexing\n",
        "inputs = ConstructVocab(fastText_wv.wv.vocab)\n",
        "\n",
        "# examples of what is in the vocab\n",
        "print(inputs.vocab[\n",
        "             :200])\n",
        "print(len(inputs.word2idx))\n",
        "print(len(inputs.vocab))\n",
        "# inputs.word2idx = load_from_pickle('/content/drive/My Drive/Research_Shanto/Datasets/Ashik Bhai_Sentiment/Code/char_indices.pkl')\n",
        "# inputs.idx2word = load_from_pickle('/content/drive/My Drive/Research_Shanto/Datasets/Ashik Bhai_Sentiment/Code/indices_char.pkl')\n",
        "# weights = load_from_pickle('/content/drive/My Drive/Research_Shanto/Datasets/Ashik Bhai_Sentiment/Code/embedded.pkl')\n",
        "# print(inputs.word2idx['<pad>'])          \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkYEejXNP6QA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vectorize to tensor\n",
        "input_tensor = [[ inputs.word2idx[s] if s in inputs.word2idx else '<pad>' for s in es.split()]  for es in data[\"Data\"].values.tolist()]\n",
        "input_tensor[0:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EMgi0LX_tdB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vocab = set()\n",
        "# for t in inputs.word2idx:\n",
        "#   vocab.update(t)\n",
        "# inputs.vocab = vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNQgQtvmCsoj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(inputs.vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW3OXbip6o3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(inputs.idx2word))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUNkDeOlL35Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(inputs.word2idx)\n",
        "# print(inputs.word2idx[' '])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qqf0tC3FSuCk",
        "colab_type": "text"
      },
      "source": [
        "### 3.2 Converting Data into Tensors \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8T8gf8NGuB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.Sentiment.value_counts().plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omlfNU8hSuCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vectorize to tensor\n",
        "input_tensor = []\n",
        "for es in data[\"Data\"]:\n",
        "  temp = []\n",
        "  for s in es:\n",
        "    try:\n",
        "      temp.append(inputs.word2idx[s])\n",
        "    except:\n",
        "      temp.append(0)\n",
        "      \n",
        "  input_tensor.append(temp)\n",
        "      \n",
        "# input_tensor = [[inputs.word2idx[t] for t in s.plit() ] for s in es.split()  for es in data[\"Data\"].values.tolist() ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AphKgs33SuCn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# examples of what is in the input tensors\n",
        "input_tensor[0:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzoIfZHjSuCr",
        "colab_type": "text"
      },
      "source": [
        "### 3.3 Padding data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXbSHvs0SuCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zyXKoy6SuCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the max_length of input tensor\n",
        "max_length_inp = 300\n",
        "print(max_length_inp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lKqBn7fdtS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# weights.size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYk71VEPSuC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_sequences(x, max_len):\n",
        "    padded = np.zeros((max_len), dtype=np.int64)\n",
        "    if len(x) > max_len: padded[:] = x[:max_len]\n",
        "    else: padded[:len(x)] = x\n",
        "    return padded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8wKDdBCSuC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# inplace padding\n",
        "input_tensor = [pad_sequences(x, max_length_inp) for x in input_tensor]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyg4r0R7Swgv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(input_tensor[:1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSVMbuVJSuC-",
        "colab_type": "text"
      },
      "source": [
        "### 3.4 Binarization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBN6xAsGSuDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### convert targets to one-hot encoding vectors\n",
        "emotions = list(set(data.Sentiment.unique()))\n",
        "num_emotions = len(emotions)\n",
        "# binarizer\n",
        "mlb = preprocessing.MultiLabelBinarizer()\n",
        "data_labels =  [set(emos) & set(emotions) for emos in data[['Sentiment']].values]\n",
        "bin_emotions = mlb.fit_transform(data_labels)\n",
        "target_tensor = np.array(bin_emotions.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_369xrpSuDC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_tensor[0:8] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLZMnNbUSuDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[0:8]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCgbz5icSuDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_emotion = lambda t: np.argmax(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bI6rF59SuDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_emotion(target_tensor[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxi-STseSuDN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# emotion_dict = {2:0, 3:1, 4:2, 1:-1, 0:-2}\n",
        "emotion_dict = {1:1, 0:0}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahRkO7WISuDN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emotion_dict[get_emotion(target_tensor[0])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MIaGDsnSTuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(get_emotion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGWDE42iSuDQ",
        "colab_type": "text"
      },
      "source": [
        "### 3.5 Split data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQQuGQReSuDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.3)\n",
        "\n",
        "# Split the validataion further to obtain a holdout dataset (for testing) -- split 50:50\n",
        "input_tensor_val, input_tensor_test, target_tensor_val, target_tensor_test = train_test_split(input_tensor_val, target_tensor_val, test_size=0.5)\n",
        "\n",
        "# Show length\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val), len(input_tensor_test), len(target_tensor_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjZ0GXI9SuDX",
        "colab_type": "text"
      },
      "source": [
        "### 3.6 Data Loader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0xtwf8nSuDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_BUFFER_SIZE = len(input_tensor_train)\n",
        "VAL_BUFFER_SIZE = len(input_tensor_val)\n",
        "TEST_BUFFER_SIZE = len(input_tensor_test)\n",
        "BATCH_SIZE = 32\n",
        "TRAIN_N_BATCH = TRAIN_BUFFER_SIZE // BATCH_SIZE\n",
        "VAL_N_BATCH = VAL_BUFFER_SIZE // BATCH_SIZE\n",
        "TEST_N_BATCH = TEST_BUFFER_SIZE // BATCH_SIZE\n",
        "\n",
        "embedding_dim = 300\n",
        "units = 512\n",
        "vocab_inp_size = len(inputs.word2idx)\n",
        "target_size = num_emotions\n",
        "print(num_emotions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMDa8eJVSuDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "# import torch.utils.data.sampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI0Of7YiSuDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert the data to tensors and pass to the Dataloader \n",
        "# to create an batch iterator\n",
        "\n",
        "\n",
        "\n",
        "class MyData(Dataset):\n",
        "\n",
        "    def __init__(self, X, y):\n",
        "        self.data = X\n",
        "        self.target = y\n",
        "        self.length = [ np.sum(1 - np.equal(x, 0)) for x in X]\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        x_len = self.length[index]\n",
        "        return x, y, x_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kgVVs1XSuDc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = MyData(input_tensor_train, target_tensor_train)\n",
        "val_dataset = MyData(input_tensor_val, target_tensor_val)\n",
        "test_dataset = MyData(input_tensor_test, target_tensor_test)\n",
        "\n",
        "train_dataset = DataLoader(train_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "val_dataset = DataLoader(val_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "test_dataset = DataLoader(test_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upQNqg9xSuDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_dataset.batch_size\n",
        "print(len(train_dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqYHyFGwSuDh",
        "colab_type": "text"
      },
      "source": [
        "## 4. Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avHYthQdSuDi",
        "colab_type": "text"
      },
      "source": [
        "### 4.1 Constructing the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9Pv-8bo6jXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def create_emb_layer(weights_matrix, non_trainable=False):\n",
        "#     num_embeddings, embedding_dim = weights_matrix.shape\n",
        "#     emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
        "#     # emb_layer.load_state_dict({'weight': weights_matrix})\n",
        "#     # if non_trainable:\n",
        "#     #     emb_layer.weight.requires_grad = False\n",
        "\n",
        "#     return emb_layer, num_embeddings, embedding_dim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOXo3GiwjD9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CnnTextClassifier(nn.Module):\n",
        "    def __init__(self, weights, vocab_size, EMBEDDING_SIZE,NUM_FILTERS = [64,100],num_classes=2, window_sizes=(3,3)):\n",
        "        super(CnnTextClassifier, self).__init__()\n",
        "        # w2vmodel = gensim.models.KeyedVectors.load('/content/drive/My Drive/Research_Shanto/pretrained/test_w2v.model')\n",
        "        \n",
        "        # With pretrained embeddings\n",
        "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(weights))\n",
        "        # Without pretrained embeddings\n",
        "        # self.embedding = nn.Embedding(vocab_size, EMBEDDING_SIZE)\n",
        "\n",
        "        self.convs = nn.ModuleList([\n",
        "                                   nn.Conv2d(1, NUM_FILTERS, [window_size, EMBEDDING_SIZE], padding=(window_size - 1, 0))\n",
        "                                   for window_size in window_sizes\n",
        "        ])\n",
        "\n",
        "        self.fc = nn.Linear(NUM_FILTERS * len(window_sizes), num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x) # [B, T, E]\n",
        "        # print(\"x.shape :\", x.shape)\n",
        "\n",
        "        # Apply a convolution + max_pool layer for each window size\n",
        "        x = torch.unsqueeze(x, 1)\n",
        "        xs = []\n",
        "        for conv in self.convs:\n",
        "            x2 = torch.relu(conv(x))\n",
        "            x2 = torch.squeeze(x2, -1)\n",
        "            # print(\"x2.shape :\",x2.shape)\n",
        "            x2 = F.max_pool1d(x2, x2.size(2))\n",
        "            xs.append(x2)\n",
        "        x = torch.cat(xs, 2)\n",
        "\n",
        "        # FC\n",
        "        x = x.view(x.size(0), -1)\n",
        "        logits = self.fc(x)\n",
        "\n",
        "        probs = F.softmax(logits, dim = 1)\n",
        "        return probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo6GVV87SuDk",
        "colab_type": "text"
      },
      "source": [
        "### 4.2 Pretesting model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjomHaHbSuDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "### sort batch function to be able to use with pad_packed_sequence\n",
        "def sort_batch(X, y, lengths):\n",
        "    lengths, indx = lengths.sort(dim=0, descending=True)\n",
        "    X = X[indx]\n",
        "    y = y[indx]\n",
        "    return X.transpose(0,1), y, lengths # transpose (batch x seq) to (seq x batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFhymNqRSuDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "n_layers = 1\n",
        "# print(vocab_inp_size, embedding_dim, (modely.wv.vocab.keys()) )\n",
        "# weights=0\n",
        "vocab_inp_size = (inputs.word2idx)\n",
        "model = CnnTextClassifier(weights, vocab_inp_size, embedding_dim )\n",
        "model.to(device)\n",
        "\n",
        "# obtain one sample from the data iterator\n",
        "it = iter(train_dataset)\n",
        "x, y, x_len = next(it)\n",
        "\n",
        "\n",
        "# sort the batch first to be able to use with pac_pack sequence\n",
        "xs, ys, lens = sort_batch(x, y, x_len)\n",
        "print(\"xs.size(0) :\", xs.size(0))\n",
        "\n",
        "print(\"Input size: \", xs.size())\n",
        "# hid = model.initialize_hidden_state(BATCH_SIZE, device)\n",
        "# hid= tuple([each.data for each in hid])\n",
        "\n",
        "\n",
        "output, _ = model(xs.to(device), lens, device)\n",
        "# print(output.size())\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqRXfA2NSuDp",
        "colab_type": "text"
      },
      "source": [
        "## 5. Training the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s9KO8c-1JEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for name, param in model.named_parameters():                \n",
        "#     if(name == \"embedding.weight\"):\n",
        "#       param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFuDTsrUSuDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Enabling cuda\n",
        "use_cuda = True if torch.cuda.is_available() else False\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = EmoGRU(weights, vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "model.to(device)\n",
        "\n",
        "### loss criterion and optimizer for training\n",
        "criterion = nn.CrossEntropyLoss() # the same as log_softmax + NLLLoss\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "def loss_function(y, prediction):\n",
        "    \"\"\" CrossEntropyLoss expects outputs and class indices as target \"\"\"\n",
        "    # convert from one-hot encoding to class indices\n",
        "    target = torch.max(y, 1)[1]\n",
        "    # print(target.shape)\n",
        "    # print(prediction.shape)\n",
        "    loss = criterion(prediction, target) \n",
        "    return loss   #TODO: refer the parameter of these functions as the same\n",
        "    \n",
        "def accuracy(target, logit):\n",
        "    ''' Obtain accuracy for training round '''\n",
        "    target = torch.max(target, 1)[1] # convert from one-hot encoding to class indices\n",
        "    # print(\"Before: \", logit)\n",
        "    logit = F.softmax(logit, dim = 1)\n",
        "    # print(\"After: \", logit)\n",
        "    corrects = (torch.max(logit, 1)[1].data == target).sum()\n",
        "    accuracy = 100.0 * corrects / len(logit)\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyvsSQrPSuDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    \n",
        "    ### Initialize hidden state\n",
        "    # TODO: do initialization here.\n",
        "    total_loss = 0\n",
        "    train_accuracy, val_accuracy = 0, 0\n",
        "    \n",
        "    ### Training\n",
        "    for (batch, (inp, targ, lens)) in enumerate(train_dataset):\n",
        "        loss = 0\n",
        "        predictions, _ = model(inp.permute(1 ,0).to(device), lens, device) # TODO:don't need _   \n",
        "              \n",
        "        loss += loss_function(targ.to(device), predictions)\n",
        "        batch_loss = (loss / int(targ.shape[1]))        \n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "        train_accuracy += batch_accuracy\n",
        "        \n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Val. Loss {:.4f}'.format(epoch + 1,\n",
        "                                                         batch,\n",
        "                                                         batch_loss.cpu().detach().numpy()))\n",
        "            \n",
        "    ### Validating\n",
        "    for (batch, (inp, targ, lens)) in enumerate(val_dataset):        \n",
        "        predictions,_ = model(inp.permute(1, 0).to(device), lens, device)        \n",
        "        batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "        val_accuracy += batch_accuracy\n",
        "    \n",
        "    print('Epoch {} Loss {:.4f} -- Train Acc. {:.4f} -- Val Acc. {:.4f}'.format(epoch + 1, \n",
        "                                                             total_loss / TRAIN_N_BATCH, \n",
        "                                                             train_accuracy / TRAIN_N_BATCH,\n",
        "                                                             val_accuracy / VAL_N_BATCH))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NXLlkwleBtH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new = \"RezaFastText_Gru\"\n",
        "name = new + str(max_length_inp) + '_' + str(EPOCHS) + '_' + str(data.shape[0]) + '_' + new + '_' + str(units) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUeHpjd_-Z1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig1 = plt.gcf()\n",
        "plt.plot(y_, train_acc, label='train_accuracy')\n",
        "plt.plot(y_, val_acc, label='validation_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.draw()\n",
        "fig1.savefig(\"/content/drive/My Drive/Research_Shanto/Datasets/Ashik Bhai_Sentiment/results/\" + name + \"_acc.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnGw7CIfeH8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig2 = plt.gcf()\n",
        "plt.plot(y_, mean_loss_t, label='loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.draw()\n",
        "fig2.savefig(\"/content/drive/My Drive/Research_Shanto/Datasets/Ashik Bhai_Sentiment/results/\" + name + \"_loss.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72jYWoxDSuDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDP6WuACi12j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# test_accuracy = 0\n",
        "# all_predictions = []\n",
        "# x_raw = []\n",
        "# y_raw = []\n",
        "\n",
        "# device = \"cuda\" # we don't need GPU to do testing\n",
        "# model.to(\"cuda\")\n",
        "\n",
        "# for (batch, (inp, targ, lens)) in (train_dataset):          \n",
        "#     predictions,_ = model(inp.permute(1, 0).to(device), lens, device)        \n",
        "#     batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "#     test_accuracy += batch_accuracy\n",
        "    \n",
        "#     x_raw = x_raw + [x for x in inp]\n",
        "#     y_raw = y_raw + [y for y in targ]\n",
        "    \n",
        "#     all_predictions.append(predictions)\n",
        "    \n",
        "# print(\"Test Accuracy: \", test_accuracy / TRAIN_N_BATCH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKiF3LKuSuDu",
        "colab_type": "text"
      },
      "source": [
        "## 6. Evaluation on the Testing Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-IORQgwSuDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_accuracy = 0\n",
        "all_predictions = []\n",
        "x_raw = []\n",
        "y_raw = []\n",
        "\n",
        "use_cuda = True if torch.cuda.is_available() else False\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "# device = \"cuda\" # we don't need GPU to do testing\n",
        "model.to(device)\n",
        "# test_ = model.initialize_hidden_state(BATCH_SIZE, device)\n",
        "\n",
        "for (batch, (inp, targ, lens)) in enumerate(test_dataset):    \n",
        "    # test_= tuple([each.data for each in test_])\n",
        "    \n",
        "    predictions,test_h = model(inp.permute(1 ,0).to(device),lens, device) \n",
        "    batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "    print(targ, predictions)\n",
        "    test_accuracy += batch_accuracy\n",
        "    \n",
        "    x_raw = x_raw + [x for x in inp]\n",
        "    y_raw = y_raw + [y for y in targ]\n",
        "    \n",
        "    all_predictions.append(predictions)\n",
        "    \n",
        "print(\"Test Accuracy: \", test_accuracy.cpu().detach().numpy() / TEST_N_BATCH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTLKA47iSuDz",
        "colab_type": "text"
      },
      "source": [
        "### 6.1 Confusion Matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM9g0v7sRTTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Class to Properly Evaluate our Models\n",
        "class Evaluate():\n",
        "\n",
        "    def va_dist(cls, prediction, target, va_df, binarizer, name='', silent=False):\n",
        "        \"\"\" Computes distance between actual and prediction through cosine distance \"\"\"\n",
        "        va_matrix = va_df.loc[binarizer.classes_][['valence','arousal']].values\n",
        "        y_va = target.dot(va_matrix)\n",
        "        F_va = prediction.dot(va_matrix)\n",
        "\n",
        "        # dist is a one row vector with size of the test data passed(emotion)\n",
        "        dist = metrics.pairwise.paired_cosine_distances(y_va, F_va)\n",
        "        res = stats.describe(dist)\n",
        "\n",
        "        # print by default (if silent=False)\n",
        "        if not silent:\n",
        "            print('%s\\tmean: %f\\tvariance: %f' % (name, res.mean, res.variance))\n",
        "\n",
        "        return {\n",
        "            'distances': dist,\n",
        "            'dist_stat': res\n",
        "        }\n",
        "\n",
        "    def evaluate_class(cls, predictions, target, target2=None, silent=False):\n",
        "        \"\"\" Compute only the predicted class \"\"\"\n",
        "        p_2_annotation = dict()\n",
        "\n",
        "        precision_recall_fscore_support = [\n",
        "            (pair[0], pair[1].mean()) for pair in zip(\n",
        "                ['precision', 'recall', 'f1', 'support'],\n",
        "                metrics.precision_recall_fscore_support(target, predictions)\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        metrics.precision_recall_fscore_support(target, predictions)\n",
        "\n",
        "        # confusion matrix\n",
        "        le = LabelEncoder()\n",
        "        target_le = le.fit_transform(target)\n",
        "        predictions_le = le.transform(predictions)\n",
        "        cm = metrics.confusion_matrix(target_le, predictions_le)\n",
        "\n",
        "        # prediction if two annotations are given on test data\n",
        "        if target2:\n",
        "            p_2_annotation = pd.DataFrame(\n",
        "                [(pred, pred in set([t1,t2])) for pred, t1, t2 in zip(predictions, target, target2)],\n",
        "                columns=['emo','success']\n",
        "            ).groupby('emo').apply(lambda emo: emo.success.sum()/ len(emo.success)).to_dict()\n",
        "\n",
        "        if not silent:\n",
        "            print(\"Default Classification report\")\n",
        "            print(metrics.classification_report(target, predictions))\n",
        "\n",
        "            # print if target2 was provided\n",
        "            if len(p_2_annotation) > 0:\n",
        "                print('\\nPrecision on 2 annotations:')\n",
        "                for emo in p_2_annotation:\n",
        "                    print(\"%s: %.2f\" % (emo, p_2_annotation[emo]))\n",
        "\n",
        "            # print accuracies, precision, recall, and f1\n",
        "            print('\\nAccuracy:')\n",
        "            print(metrics.accuracy_score(target, predictions))\n",
        "            print(\"Correct Predictions: \", metrics.accuracy_score(target, predictions,normalize=False))\n",
        "            for to_print in precision_recall_fscore_support[:3]:\n",
        "                print( \"%s: %.2f\" % to_print )\n",
        "\n",
        "            # normalizing the values of the consfusion matrix\n",
        "            print('\\nconfusion matrix\\n %s' % cm)\n",
        "            print('(row=expected, col=predicted)')\n",
        "            cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "            cls.plot_confusion_matrix(cm_normalized, le.classes_, 'Confusion matrix Normalized')\n",
        "\n",
        "        return {\n",
        "            'precision_recall_fscore_support': precision_recall_fscore_support,\n",
        "            'accuracy': metrics.accuracy_score(target, predictions),\n",
        "            'p_2_annotation': p_2_annotation,\n",
        "            'confusion_matrix': cm\n",
        "        }\n",
        "\n",
        "    def predict_class(cls, X_train, y_train, X_test, y_test,\n",
        "                      pipeline, silent=False, target2=None):\n",
        "        \"\"\" Predicted class,then run some performance evaluation \"\"\"\n",
        "        pipeline.fit(X_train, y_train)\n",
        "        predictions = pipeline.predict(X_test)\n",
        "        print(\"predictions computed....\")\n",
        "        return cls.evaluate_class(predictions, y_test, target2, silent)\n",
        "\n",
        "    def evaluate_prob(cls, prediction, target_rank, target_class, binarizer, va_df, silent=False, target2=None):\n",
        "        \"\"\" Evaluate through probability \"\"\"\n",
        "        # Run normal class evaluator\n",
        "        predict_class = binarizer.classes_[prediction.argmax(axis=1)]\n",
        "        class_eval = cls.evaluate_class(predict_class, target_class, target2, silent)\n",
        "\n",
        "        if not silent:\n",
        "            print('\\n - First Emotion Classification Metrics -')\n",
        "            print('\\n - Multiple Emotion rank Metrics -')\n",
        "            print('VA Cosine Distance')\n",
        "\n",
        "        classes_dist = [\n",
        "            (\n",
        "                emo,\n",
        "                cls.va_dist(\n",
        "                    prediction[np.array(target_class) == emo],\n",
        "                    target_rank[np.array(target_class) == emo],\n",
        "                    va_df,\n",
        "                    binarizer,\n",
        "                    emo,\n",
        "                    silent)\n",
        "                ) for emo in binarizer.classes_\n",
        "        ]\n",
        "        avg_dist = cls.va_dist(prediction, target_rank, va_df, binarizer, 'avg', silent)\n",
        "\n",
        "        coverage_error = metrics.coverage_error(target_rank, prediction)\n",
        "        average_precision_score = metrics.average_precision_score(target_rank, prediction)\n",
        "        label_ranking_average_precision_score = metrics.label_ranking_average_precision_score(target_rank, prediction)\n",
        "        label_ranking_loss = metrics.label_ranking_loss(target_rank, prediction)\n",
        "\n",
        "        # recall at 2\n",
        "        # obtain top two predictions\n",
        "        top2_pred = [set([binarizer.classes_[i[0]], binarizer.classes_[i[1]]]) for i in (prediction.argsort(axis=1).T[-2:].T)]\n",
        "        recall_at_2 = pd.DataFrame(\n",
        "            [\n",
        "            t in p for t, p in zip(target_class, top2_pred)\n",
        "            ], index=target_class, columns=['recall@2']).groupby(level=0).apply(lambda emo: emo.sum()/len(emo))\n",
        "\n",
        "        # combine target into sets\n",
        "        if target2:\n",
        "            union_target = [set(t) for t in zip(target_class, target2)]\n",
        "        else:\n",
        "            union_target = [set(t) for t in zip(target_class)]\n",
        "\n",
        "        # precision at k\n",
        "        top_k_pred = [\n",
        "            [set([binarizer.classes_[i] for i in i_list]) for i_list in (prediction.argsort(axis=1).T[-i:].T)]\n",
        "            for i in range(2, len(binarizer.classes_)+1)]\n",
        "        precision_at_k = [\n",
        "            ('p@' + str(k+2), np.array([len(t & p)/(k+2) for t, p in zip(union_target, top_k_pred[k])]).mean())\n",
        "            for k in range(len(top_k_pred))]\n",
        "\n",
        "        # do this if silent= False\n",
        "        if not silent:\n",
        "            print('\\n')\n",
        "            print(recall_at_2)\n",
        "            print('\\n')\n",
        "            print('p@k')\n",
        "            for pk in precision_at_k:\n",
        "                print(pk[0] + ':\\t' + str(pk[1]))\n",
        "            print('\\ncoverage_error: %f' % coverage_error)\n",
        "            print('average_precision_score: %f' % average_precision_score)\n",
        "            print('label_ranking_average_precision_score: %f' % label_ranking_average_precision_score)\n",
        "            print('label_ranking_loss: %f' % label_ranking_loss)\n",
        "\n",
        "        return {\n",
        "            'class_eval': class_eval,\n",
        "            'recall_at_2': recall_at_2.to_dict(),\n",
        "            'precision_at_2': precision_at_k,\n",
        "            'classes_dist': classes_dist,\n",
        "            'avg_dist': avg_dist,\n",
        "            'coverage_error': coverage_error,\n",
        "            'average_precision_score': average_precision_score,\n",
        "            'label_ranking_average_precision_score': label_ranking_average_precision_score,\n",
        "            'label_ranking_loss': label_ranking_loss\n",
        "        }\n",
        "\n",
        "\n",
        "    def predict_prob(cls, X_train, y_train, X_test, y_test, label_test, pipeline, binarizer, va_df, silent=False, target2=None):\n",
        "        \"\"\" Output predcations based on training and labels \"\"\"\n",
        "        pipeline.fit(X_train, y_train)\n",
        "        predictions = pipeline.predict_proba(X_test)\n",
        "        pred_to_mlb = [np.where(pipeline.classes_ == emo)[0][0] for emo in binarizer.classes_.tolist()]\n",
        "        return cls.evaluate_prob(predictions[:,pred_to_mlb], y_test, label_test, binarizer, va_df, silent, target2)\n",
        "\n",
        "\n",
        "    def plot_confusion_matrix(cls, cm, my_tags, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "        \"\"\" Plotting the confusion_matrix\"\"\"\n",
        "        plt.rc('figure', figsize=(4, 4), dpi=100)\n",
        "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "        plt.title(title)\n",
        "        plt.colorbar()\n",
        "        tick_marks = np.arange(len(my_tags))\n",
        "        target_names = my_tags\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "        \n",
        "        # add normalized values inside the Confusion matrix\n",
        "        fmt = '.2f'\n",
        "        thresh = cm.max() / 2.\n",
        "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "            plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.ylabel('True label')\n",
        "        plt.xlabel('Predicted label')\n",
        "        plt.savefig('/content/drive/My Drive/Research_Shanto/Datasets/Ashik Bhai_Sentiment/results/' + name +'_confusion.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBUWz-LBSuDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluator = Evaluate()\n",
        "\n",
        "final_predictions = []\n",
        "\n",
        "for p in all_predictions:\n",
        "    for sub_p in p:\n",
        "        final_predictions.append(sub_p.cpu().detach().numpy())\n",
        "        \n",
        "predictions = [np.argmax(p).item() for p in final_predictions]\n",
        "targets = [np.argmax(t).item() for t in y_raw]\n",
        "correct_predictions = float(np.sum(predictions == targets))\n",
        "\n",
        "# predictions\n",
        "predictions_human_readable = ((x_raw, predictions))\n",
        "# actual targets\n",
        "target_human_readable = ((x_raw,  targets))\n",
        "\n",
        "# emotion_dict = {0: '0', 1: '-1', 2: '-2', 3: '1', 4: '2'}\n",
        "emotion_dict = {1:1, 0:0,2:2}\n",
        "# convert results into dataframe\n",
        "model_test_result = pd.DataFrame(predictions_human_readable[1],columns=[\"emotion\"])\n",
        "test = pd.DataFrame(target_human_readable[1], columns=[\"emotion\"])\n",
        "\n",
        "model_test_result.emotion = model_test_result.emotion.map(lambda x: emotion_dict[int(float(x))])\n",
        "test.emotion = test.emotion.map(lambda x: emotion_dict[int(x)])\n",
        "\n",
        "evaluator.evaluate_class(model_test_result.emotion, test.emotion );"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVWQEMO67qSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}